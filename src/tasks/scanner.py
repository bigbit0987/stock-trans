#!/usr/bin/env python
"""
å°¾ç›˜é€‰è‚¡æ‰«æä»»åŠ¡
å»ºè®®åœ¨ 14:35 - 14:50 è¿è¡Œ
"""
import os
import sys
import datetime
import pandas as pd
import glob

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
# è·¯å¾„å±‚çº§: src/tasks/scanner.py -> src/tasks/ -> src/ -> stock_trans/
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT)

import akshare as ak
from concurrent.futures import ThreadPoolExecutor, as_completed
from config import STRATEGY, RESULTS_DIR, CONCURRENT, RISK_CONTROL, RPS_DATA_DIR, CAPITAL
from src.data_loader import get_realtime_quotes, load_latest_rps, get_stock_history, get_cache_stats, get_tail_volume_ratio
from src.strategy import filter_by_basic_conditions, generate_signal
from src.utils import logger


def check_market_risk(realtime_df: pd.DataFrame = None) -> tuple:
    """
    æ£€æŸ¥å¤§ç›˜é£é™© (å¢å¼ºç‰ˆ: æŒ‡æ•° + æ¶¨è·Œå®¶æ•°)
    
    é£æ§é€»è¾‘:
    1. ç›‘æ§ä¸Šè¯æŒ‡æ•°æ¶¨è·Œå¹…ï¼Œé˜²æ­¢å¤§ç›˜æš´è·Œé£é™©
    2. è®¡ç®—å¸‚åœºèµšé’±æ•ˆåº”ï¼ˆä¸Šæ¶¨å®¶æ•°å æ¯”ï¼‰ï¼Œåˆ¤æ–­å¸‚åœºæƒ…ç»ª
    3. ç»“åˆæŒ‡æ•°å’Œå¸‚åœºæƒ…ç»ªç»™å‡ºç»¼åˆé£é™©è¯„çº§
    
    Args:
        realtime_df: å¯é€‰ï¼Œå¦‚æœå·²ç»è·å–äº†å®æ—¶è¡Œæƒ…ï¼Œç›´æ¥å¤ç”¨ï¼Œé¿å…é‡å¤è·å–æ•°æ®
    
    Returns:
        tuple: (æ˜¯å¦å®‰å…¨, ä¸Šè¯æ¶¨è·Œå¹…, èµšé’±æ•ˆåº”)
            - æ˜¯å¦å®‰å…¨: boolï¼ŒTrueè¡¨ç¤ºå¸‚åœºé£é™©å¯æ§ï¼Œå¯ä»¥æ­£å¸¸äº¤æ˜“
            - ä¸Šè¯æ¶¨è·Œå¹…: floatï¼Œä¸Šè¯æŒ‡æ•°å½“æ—¥æ¶¨è·Œå¹…ç™¾åˆ†æ¯”
            - èµšé’±æ•ˆåº”: floatï¼Œä¸Šæ¶¨è‚¡ç¥¨å®¶æ•°å æ¯”ï¼ˆ0-1ä¹‹é—´ï¼‰
    
    é£æ§æ ‡å‡†:
        - æŒ‡æ•°è·Œå¹…è¶…è¿‡é˜ˆå€¼ï¼ˆé»˜è®¤-1.5%ï¼‰æ—¶è§†ä¸ºé£é™©
        - ä¸Šæ¶¨å®¶æ•°å æ¯”ä½äºé˜ˆå€¼ï¼ˆé»˜è®¤20%ï¼‰æ—¶è§†ä¸ºæƒ…ç»ªå†°ç‚¹
        - ä»»ä¸€æ¡ä»¶è§¦å‘éƒ½ä¼šåˆ¤å®šä¸ºå¸‚åœºé£é™©è¾ƒé«˜
    """
    try:
        # 1. æŒ‡æ•°è·Œå¹…
        index_df = ak.stock_zh_index_spot_em()
        sh_idx = index_df[index_df['ä»£ç '] == '000001']
        sh_pct = sh_idx.iloc[0]['æ¶¨è·Œå¹…'] if not sh_idx.empty else 0
        
        # 2. å¸‚åœºæƒ…ç»ªï¼ˆæ¶¨è·Œå®¶æ•°ï¼‰
        if realtime_df is not None:
            market_df = realtime_df
        else:
            market_df = ak.stock_zh_a_spot_em()
        
        up_count = len(market_df[market_df['pct_change'] > 0])
        down_count = len(market_df[market_df['pct_change'] < 0])
        total = up_count + down_count
        
        # èµšé’±æ•ˆåº”: ä¸Šæ¶¨å®¶æ•°å æ¯”
        sentiment = up_count / total if total > 0 else 0.5
        
        logger.info(f"   ä¸Šè¯æŒ‡æ•°: {sh_pct:+.2f}%")
        logger.info(f"   æ¶¨/è·Œå®¶æ•°: {up_count}/{down_count} (èµšé’±æ•ˆåº”: {sentiment:.0%})")
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é˜ˆå€¼
        drop_threshold = RISK_CONTROL.get('market_drop_threshold', -1.5)
        sentiment_threshold = RISK_CONTROL.get('sentiment_threshold', 0.2)
        
        # åˆ¤å®šé€»è¾‘: æŒ‡æ•°å¤§è·Œ OR å…¨åœºæ™®è·Œ
        is_safe = (sh_pct > drop_threshold) and (sentiment > sentiment_threshold)
        
        return is_safe, sh_pct, sentiment
        
    except Exception as e:
        logger.error(f"   âš ï¸ é£æ§æ£€æŸ¥å‡ºé”™: {e}")
        logger.warning(f"   âš ï¸ é»˜è®¤è¿”å›\"ä¸å®‰å…¨\"ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ")
        return False, 0, 0  # é£æ§å¤±è´¥æ—¶é»˜è®¤ä¸å®‰å…¨ï¼


def run_scan():
    """è¿è¡Œå°¾ç›˜æ‰«æ
    
    ä¸»è¦åŠŸèƒ½:
    1. æ£€æŸ¥å¤§ç›˜é£é™©çŠ¶æ€
    2. è·å–å®æ—¶è¡Œæƒ…æ•°æ®
    3. å¤šè½®ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
    4. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’ŒRPSå¼ºåº¦
    5. ç”Ÿæˆé€‰è‚¡ä¿¡å·å’Œäº¤æ˜“å»ºè®®
    
    è¿è¡Œæ—¶é—´å»ºè®®: 14:35-14:50 (å°¾ç›˜æ—¶æ®µ)
    """
    logger.info("=" * 60)
    logger.info("ğŸš€ å°¾ç›˜é€‰è‚¡æ‰«æå¯åŠ¨ (å¤šå› å­å¢å¼ºç‰ˆ v2.3)")
    logger.info(f"   æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
    try:
        cache_stats = get_cache_stats()
        logger.info(f"\nğŸ“¦ ç¼“å­˜çŠ¶æ€: å†å²æ•°æ® {cache_stats['history_cached']} åª, åŠ¨é‡ {cache_stats['momentum_cached']} åª")
    except Exception:
        pass
    
    # æ£€æŸ¥æ˜¯å¦å‘¨æœ«
    weekday = datetime.datetime.today().weekday()
    if weekday >= 5:
        logger.warning("\nâš ï¸ è­¦å‘Šï¼šä»Šå¤©æ˜¯å‘¨æœ«ï¼ŒAè‚¡ä¸å¼€å¸‚ï¼Œæ•°æ®å¯èƒ½æœªæ›´æ–°ï¼")
    
    # =========================================
    # å¤§ç›˜é£æ§æ£€æŸ¥ (å¢å¼ºç‰ˆ)
    # =========================================
    position_multiplier = 1.0  # v2.5.1: ä»“ä½ä¹˜æ•°ï¼Œç”¨äºå¸‚åœºå®½åº¦æ¸è¿›å¼é£æ§
    rps_min_dynamic = STRATEGY.get('rps_min', 40)  # v2.5.2: åŠ¨æ€ RPS é˜ˆå€¼
    check_turnover_spike = False  # v2.5.2: è¿‡çƒ­æœŸæ¢æ‰‹ç‡çªå˜æ£€æµ‹æ ‡è®°
    breadth_pct = 10  # v2.5.2: å¸‚åœºå®½åº¦ç™¾åˆ†æ¯”ï¼Œé»˜è®¤ 10%ï¼ˆç¨åå¯èƒ½è¢«è¦†ç›–ï¼‰
    
    try:
        from config import MARKET_RISK_CONTROL
        from src.factors import get_market_condition, print_market_condition
        
        if MARKET_RISK_CONTROL.get('enabled', True):
            market_cond = print_market_condition()
            
            # =========================================
            # v2.5.2: Market Breadth æ¸è¿›å¼é£æ§ï¼ˆå¢å¼ºç‰ˆï¼‰
            # æ ¹æ®å¸‚åœºå®½åº¦åŠ¨æ€è°ƒæ•´æ“ä½œç­–ç•¥å’Œç­›é€‰æ ‡å‡†
            # =========================================
            breadth = market_cond.get('market_breadth', {})
            breadth_pct = breadth.get('breadth_pct', 10)  # é»˜è®¤ 10%
            
            # è·å–è‡ªé€‚åº”é…ç½®
            adaptive_config = MARKET_RISK_CONTROL.get('market_breadth_adaptive', {})
            
            if breadth_pct < 4:
                # æå¼±å¸‚åœºï¼šä¼‘çœ æ¨¡å¼
                logger.warning(f"\nğŸ›‘ å¸‚åœºå®½åº¦é¢„è­¦: ä»… {breadth_pct}% åˆ›æ–°é«˜ (æå¼±)")
                logger.warning("   è§¦å‘ä¼‘çœ æ¨¡å¼ï¼Œä»Šæ—¥åœæ­¢é€‰è‚¡ï¼")
                
                from src.notifier import notify_all
                notify_all("ç³»ç»Ÿè¿›å…¥ä¼‘çœ æ¨¡å¼ ğŸ’¤", 
                          f"è§¦å‘æ¡ä»¶: å¸‚åœºå®½åº¦ä»… {breadth_pct}%ï¼ˆåˆ›20æ—¥æ–°é«˜å®¶æ•°å æ¯”æä½ï¼‰\n\n"
                          "åˆ†æ: æ€å¼ºåŠ¿è‚¡è¡Œæƒ…ï¼Œå³ä½¿æŒ‡æ•°æŠ¤ç›˜ï¼Œä¸ªè‚¡ä¹Ÿä¼šæ™®è·Œã€‚\n"
                          "å»ºè®®: ç©ºä»“è§‚æœ›ï¼Œç­‰å¾…å¸‚åœºæƒ…ç»ªå›æš–ã€‚")
                return []
            elif breadth_pct < adaptive_config.get('cold_market', {}).get('threshold', 8):
                # v2.5.2: å†°ç‚¹æœŸ - åªåšæœ€å¼ºæ ¸å¿ƒæ ‡çš„
                cold_config = adaptive_config.get('cold_market', {})
                position_multiplier = cold_config.get('position_multiplier', 0.5)
                rps_min_dynamic = cold_config.get('rps_min_override', 70)
                
                logger.warning(f"\nâš ï¸ å¸‚åœºå®½åº¦åå¼±: {breadth_pct}% åˆ›æ–°é«˜ (å†°ç‚¹æœŸ)")
                logger.warning(f"   æ¸è¿›å¼é£æ§: å•ç¬”é‡‘é¢ Ã—{position_multiplier}, RPS é˜ˆå€¼æé«˜è‡³ {rps_min_dynamic}")
            elif breadth_pct > adaptive_config.get('hot_market', {}).get('threshold', 30):
                # v2.5.2: è¿‡çƒ­æœŸ - å¯ç”¨æ¢æ‰‹ç‡çªå˜æ£€æµ‹
                hot_config = adaptive_config.get('hot_market', {})
                if hot_config.get('turnover_spike_check', True):
                    check_turnover_spike = True
                    logger.warning(f"\nğŸ”¥ å¸‚åœºè¿‡çƒ­é¢„è­¦: {breadth_pct}% åˆ›æ–°é«˜")
                    logger.warning(f"   å¯ç”¨æ¢æ‰‹ç‡çªå˜æ£€æµ‹ï¼Œè¿‡æ»¤æƒ…ç»ªè¿‡çƒ­ä¸ªè‚¡")
            else:
                logger.info(f"\nâœ… å¸‚åœºå®½åº¦è‰¯å¥½: {breadth_pct}% åˆ›æ–°é«˜ ({breadth.get('status', '')})")
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢äº¤æ˜“ (åŸæœ‰é€»è¾‘)
            is_risky = not market_cond['safe']
            
            # è·å–é£æ§é…ç½®
            risk_config = MARKET_RISK_CONTROL
            sleep_mode = risk_config.get('sleep_mode', {})
            
            if is_risky and risk_config.get('enabled', True):
                # æ£€æŸ¥æ˜¯å¦è§¦å‘ä¼‘çœ æ¨¡å¼
                if sleep_mode.get('enabled', False):
                    trigger = sleep_mode.get('trigger', 'below_ma20')
                    should_sleep = False
                    reason = ""
                    
                    if trigger == 'below_ma20' and not market_cond.get('above_ma20', True):
                        should_sleep = True
                        reason = "å¤§ç›˜è·Œç ´20æ—¥å‡çº¿ (ç©ºå¤´è¶‹åŠ¿)"
                    elif market_cond.get('index_change', 0) < risk_config.get('index_drop_threshold', -2.0):
                        should_sleep = True
                        reason = f"å¤§ç›˜æš´è·Œ ({market_cond.get('index_change'):.2f}%)"
                    
                    if should_sleep:
                        msg = f"ğŸ›‘ è§¦å‘ä¼‘çœ æ¨¡å¼: {reason}"
                        logger.warning(f"\n{msg}")
                        
                        if sleep_mode.get('notify_on_sleep', True):
                             from src.notifier import notify_all
                             notify_all("ç³»ç»Ÿè¿›å…¥ä¼‘çœ æ¨¡å¼ ğŸ’¤", f"è§¦å‘æ¡ä»¶: {reason}\n\nå»ºè®®: å¸‚åœºé£é™©è¾ƒé«˜ï¼Œç³»ç»Ÿå·²æš‚åœé€‰è‚¡ï¼Œå»ºè®®ç©ºä»“è§‚æœ›ã€‚")
                        
                        return []

                # æ—§ç‰ˆå…¼å®¹é€»è¾‘
                action = risk_config.get('below_ma20_action', 'warn')
                if action == 'stop':
                    logger.warning("\nğŸ›‘ å¤§ç›˜é£æ§è§¦å‘ï¼Œä»Šæ—¥åœæ­¢é€‰è‚¡ï¼")
                    return []
                elif action == 'warn':
                    logger.warning("\nâš ï¸ å¤§ç›˜é£æ§è­¦å‘Šï¼Œå»ºè®®è°¨æ…æ“ä½œï¼")
    except Exception as e:
        logger.warning(f"å¤§ç›˜é£æ§æ£€æŸ¥å¤±è´¥: {e}")
    # =========================================
    
    # è·å–å®æ—¶è¡Œæƒ… (å…ˆè·å–ï¼Œç”¨äºé£æ§å’Œç­›é€‰)
    df = get_realtime_quotes()
    
    # æ£€æŸ¥å¤§ç›˜é£é™© (å¤ç”¨å·²è·å–çš„æ•°æ®) - ç®€åŒ–ç‰ˆæ£€æŸ¥
    logger.info("\nğŸ“Š æ£€æŸ¥å¸‚åœºæƒ…ç»ª...")
    is_safe, sh_pct, sentiment = check_market_risk(df)
    if not is_safe:
        logger.warning("\nâš ï¸ å¸‚åœºé£é™©è¾ƒé«˜ï¼Œå»ºè®®ä»Šæ—¥è§‚æœ›ï¼")
        logger.warning("   (æŒ‡æ•°å¤§è·Œ æˆ– èµšé’±æ•ˆåº”ä½äº20%)")
        # ä»ç„¶ç»§ç»­æ‰«æï¼Œä½†ç»™å‡ºè­¦å‘Š
    
    # åŠ è½½ RPS æ•°æ®
    rps_df = load_latest_rps()
    has_rps = rps_df is not None
    if not has_rps:
        logger.error("âš ï¸ æœªæ‰¾åˆ° RPS æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ update_rps.py")
    else:
        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¿‡æœŸ (Data Integrity)
        list_of_files = glob.glob(os.path.join(RPS_DATA_DIR, 'rps_rank_*.csv'))
        if list_of_files:
            latest_file = max(list_of_files, key=os.path.getctime)
            file_date_str = os.path.basename(latest_file).split('_')[-1].replace('.csv', '')
            today_str = datetime.datetime.now().strftime('%Y%m%d')
            
            if file_date_str != today_str:
                logger.warning("!" * 60)
                logger.warning(f"âš ï¸ è­¦å‘Š: ä½¿ç”¨çš„ RPS æ•°æ®è¿‡æœŸï¼({file_date_str})")
                logger.warning("   å»ºè®®å…ˆè¿è¡Œ: python main.py update")
                logger.warning("!" * 60)
    
    # ç¬¬ä¸€è½®ç­›é€‰: ç»Ÿè®¡æ•°æ®ç­›é€‰ (ä»·æ ¼ã€æ¶¨å¹…ã€æˆäº¤é‡ã€é‡æ¯”ã€MA5ä¹–ç¦»ç­‰)
    logger.info("\nğŸ” ç¬¬ä¸€è½®ç­›é€‰: åŸºç¡€æ¡ä»¶ç­›é€‰ä¸­...")
    candidates = filter_by_basic_conditions(df)
    logger.info(f"   ç¬¦åˆåˆé€‰æ¡ä»¶: {len(candidates)} åª")
    
    if candidates.empty:
        logger.info("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ ‡çš„")
        return
        
    # ç¬¬äºŒè½®ç­›é€‰: å¹¶å‘è·å–å†å²æ•°æ®è®¡ç®— MA5 è¶‹åŠ¿å’Œ RPS è¯„åˆ†
    logger.info("\nğŸ” ç¬¬äºŒè½®ç­›é€‰: è®¡ç®— MA5 è¶‹åŠ¿å’Œ RPS å¼ºåº¦...")
    signals = []
    
    # å‡†å¤‡å·¥ä½œ
    codes = candidates['code'].tolist()
    names = candidates['name'].tolist()
    closes = candidates['close'].tolist()
    
    max_workers = CONCURRENT.get('max_workers', 10)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # å‡†å¤‡æ•°æ®å­—å…¸ï¼Œæ–¹ä¾¿çº¿ç¨‹ä¸­ä½¿ç”¨
        stock_data_map = {}
        for _, row in candidates.iterrows():
            stock_data_map[row['code']] = {
                'name': row['name'],
                'current_close': row['close'],
                'pct_change': row['pct_change'],
                'turnover': row['turnover'],
                'volume_ratio': row['volume_ratio'],
                'amplitude': row['amplitude']
            }

        # v2.5.1: åªè·å–å†å²æ•°æ®ï¼Œå°¾ç›˜æ•°æ®å»¶è¿Ÿåˆ°å‰10åç¡®è®¤é˜¶æ®µ
        # é¿å…é«˜é¢‘è°ƒç”¨åˆ†é’Ÿçº¿ API å¯¼è‡´ IP å°ç¦
        future_to_stock = {
            executor.submit(get_stock_history, code): code 
            for code in stock_data_map.keys()
        }
        
        for future in as_completed(future_to_stock):
            code = future_to_stock[future]
            try:
                hist = future.result()
                
                # ---ã€é˜²æ­¢æœªæ¥å‡½æ•°ã€‘---
                # ç¡®ä¿ hist ä¸­ä¸åŒ…å«ä»Šå¤©æ­£åœ¨äº¤æ˜“çš„ K çº¿æ•°æ®
                if hist is not None and not hist.empty:
                    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
                    # ç»Ÿä¸€æ—¥æœŸæ ¼å¼è¿›è¡Œå¯¹æ¯”
                    hist['æ—¥æœŸ_str'] = pd.to_datetime(hist['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                    if hist.iloc[-1]['æ—¥æœŸ_str'] == today_str:
                        hist = hist.iloc[:-1] # åˆ‡é™¤ä»Šå¤©ï¼Œåªä¿ç•™åˆ°æ˜¨å¤©çš„çº¯å‡€å†å²æ•°æ®
                
                if hist is not None and len(hist) >= 5:
                    data = stock_data_map[code]
                    
                    # è®¡ç®— RPS (å¦‚æœå­˜åœ¨)
                    rps_score = 0
                    sector_rps = 0
                    rps_change = 0
                    sector_name = ''  # æ¿å—åç§°ï¼Œç”¨äºæ¿å—æ»¤ç½‘
                    
                    if has_rps:
                        rps_row = rps_df[rps_df['code'] == code]
                        if not rps_row.empty:
                            row_data = rps_row.iloc[0]
                            # ä½¿ç”¨ pd.notna æ£€æŸ¥ç©ºå€¼ï¼Œç¡®ä¿ä¸ä¼šä¼ é€’ NaN
                            rps_val = row_data.get('rps', 0)
                            rps_score = rps_val if pd.notna(rps_val) else 0
                            sector_rps_val = row_data.get('sector_rps', 0)
                            sector_rps = sector_rps_val if pd.notna(sector_rps_val) else 0
                            rps_change_val = row_data.get('rps_change', 0)
                            rps_change = rps_change_val if pd.notna(rps_change_val) else 0
                            sector_val = row_data.get('sector', '')
                            sector_name = sector_val if pd.notna(sector_val) else ''  # è·å–æ¿å—åç§°
                            
                            # v2.5.0: è·å– RPS20 (çŸ­å‘¨æœŸåŠ¨é‡)
                            rps20_val = row_data.get('rps20', 0)
                            rps20_score = rps20_val if pd.notna(rps20_val) else 0
                    
                    # v2.5.2: åŠ¨æ€ RPS é˜ˆå€¼è¿‡æ»¤
                    if rps_score < rps_min_dynamic:
                        continue  # å†°ç‚¹æœŸåªä¿ç•™é«˜ RPS æ ‡çš„
                    
                    # v2.5.2: è¿‡çƒ­æœŸæ¢æ‰‹ç‡çªå˜æ£€æµ‹
                    if check_turnover_spike and 'volume' in hist.columns:
                        avg_volume_5d = hist['volume'].tail(5).mean()
                        current_volume = data.get('volume', 0) if 'volume' in data else 0
                        if current_volume > 0 and avg_volume_5d > 0:
                            spike_ratio = MARKET_RISK_CONTROL.get('market_breadth_adaptive', {}).get(
                                'hot_market', {}).get('turnover_spike_ratio', 3.0)
                            if current_volume / avg_volume_5d > spike_ratio:
                                logger.debug(f"   {code} æ¢æ‰‹ç‡çªå˜ ({current_volume/avg_volume_5d:.1f}å€)ï¼Œè¿‡çƒ­æœŸè¿‡æ»¤")
                                continue
                    
                    # æå–å‰ä¸€å¤©æ•°æ® (hist çš„æœ€åä¸€è¡Œé€šå¸¸æ˜¯å‰ä¸€ä¸ªäº¤æ˜“æ—¥)
                    prev_day = hist.iloc[-1]
                    prev_close = prev_day['close']
                    prev_open = prev_day['open']
                    prev_pct = prev_day['pct_change']
                    
                    hist_closes = hist['close'].tolist()
                    
                    # è·å–å†å²æˆäº¤é‡
                    hist_volumes = hist['volume'].tolist() if 'volume' in hist.columns else []
                    
                    # è°ƒç”¨é€šç”¨ä¿¡å·ç”Ÿæˆå‡½æ•° (v2.5.1: å°¾ç›˜æ•°æ®å»¶è¿Ÿè·å–)
                    strategy_result = generate_signal(
                        code, data['name'], data['current_close'], 
                        data['pct_change'], data['turnover'], data['volume_ratio'], data['amplitude'],
                        hist_closes, prev_close, prev_open, prev_pct, rps_score,
                        sector_rps, rps_change, rps20_score, hist_volumes, 
                        tail_vol_ratio=0  # å»¶è¿Ÿåˆ°å‰10åç¡®è®¤é˜¶æ®µå†è·å–
                    )
                    
                    if strategy_result:
                        # æ·»åŠ æ¿å—åç§°ï¼ˆç”¨äºæ¿å—æ»¤ç½‘åŠŸèƒ½ï¼‰
                        strategy_result['sector'] = sector_name
                        
                        # ---ã€è®¡ç®—å»ºè®®ä»“ä½ã€‘---
                        target_amt = CAPITAL.get('target_amount_per_stock', 0)
                        if target_amt > 0:
                            # ä¸ºæ¯åªè‚¡ç¥¨è®¡ç®—å»ºè®®æ‰‹æ•° (å‘ä¸‹å–æ•´åˆ° 100 è‚¡)
                            current_price = strategy_result['close']
                            suggested_vol = int(target_amt / current_price / 100) * 100
                            strategy_result['suggested_volume'] = f"{suggested_vol} è‚¡"
                        
                        signals.append(strategy_result)
            except Exception as e:
                logger.error(f"   âš ï¸ å¤„ç† {code} å‡ºé”™: {e}")
                
    # æ’åºå’Œè¾“å‡ºç»“æœ
    if not signals:
        logger.info("\nâŒ ä»Šæ—¥æœªå‘ç°æ¨èä¹°å…¥æ ‡çš„")
        return []
    
    # =========================================
    # å¤šå› å­è¯„åˆ† (v2.3 æ–°å¢)
    # =========================================
    try:
        from config import MULTI_FACTOR
        from src.factors import batch_calculate_scores, get_hot_sectors
        
        if MULTI_FACTOR.get('enabled', True):
            logger.info("\nğŸ“Š ç¬¬ä¸‰è½®ç­›é€‰: å¤šå› å­ç»¼åˆè¯„åˆ†...")
            
            # æ˜¾ç¤ºçƒ­é—¨æ¿å—
            hot_sectors = get_hot_sectors(5)
            if hot_sectors:
                logger.info(f"   ğŸ”¥ ä»Šæ—¥çƒ­é—¨æ¿å—: {', '.join([s['name'] for s in hot_sectors])}")
            
            # è®¡ç®—å¤šå› å­è¯„åˆ†
            scored_signals = batch_calculate_scores(signals)
            
            # æŒ‰ç»¼åˆå¾—åˆ†è¿‡æ»¤å’Œæ’åº
            min_score = MULTI_FACTOR.get('min_total_score', 60)
            scored_signals = [s for s in scored_signals if s.get('total_score', 0) >= min_score]
            
            if scored_signals:
                signals = scored_signals
                logger.info(f"   âœ… å¤šå› å­ç­›é€‰å: {len(signals)} åª (ç»¼åˆè¯„åˆ† â‰¥ {min_score})")
            else:
                logger.warning(f"   âš ï¸ å¤šå› å­ç­›é€‰åæ— ç¬¦åˆæ¡ä»¶è‚¡ç¥¨ (æœ€ä½è¦æ±‚: {min_score}åˆ†)")
    except Exception as e:
        logger.warning(f"å¤šå› å­è¯„åˆ†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ’åº: {e}")
    
    # =========================================
    # æ¿å—æ»¤ç½‘ (v2.3.1 æ–°å¢)
    # =========================================
    try:
        from config import SECTOR_FILTER
        from src.indicators import is_sector_strong
        from src.factors import get_hot_sectors, get_stock_sector
        
        if SECTOR_FILTER.get('enabled', True):
            top_pct = SECTOR_FILTER.get('top_pct', 0.33)
            all_sectors = get_hot_sectors(100)  # è·å–æ‰€æœ‰æ¿å—æ’å
            
            before_count = len(signals)
            filtered_signals = []
            
            for s in signals:
                code = s.get('ä»£ç ', '')
                # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„æ¿å—ä¿¡æ¯ï¼ˆæ¥è‡ªbatch_calculate_scoresæˆ–RPSæ•°æ®ï¼‰
                # é¿å…é€ä¸ªè°ƒç”¨get_stock_sectorå¯¼è‡´æ€§èƒ½é—®é¢˜
                sector = s.get('æ¿å—', '') or s.get('sector', '')
                if not sector:
                    # åªæœ‰åœ¨æ²¡æœ‰æ¿å—ä¿¡æ¯æ—¶æ‰å°è¯•è·å–ï¼ˆä½†è¿™åº”è¯¥å¾ˆå°‘å‘ç”Ÿï¼‰
                    sector = get_stock_sector(code)
                
                if sector and is_sector_strong(sector, all_sectors, top_pct):
                    filtered_signals.append(s)
                elif s.get('grade') == 'A':
                    # Açº§è‚¡ç¥¨ä¸å—æ¿å—é™åˆ¶
                    filtered_signals.append(s)
                elif not sector:
                    # æ— æ³•è·å–æ¿å—ä¿¡æ¯çš„è‚¡ç¥¨ä¹Ÿæ”¾è¡Œï¼ˆä¸å› æ•°æ®é—®é¢˜é”™è¿‡æœºä¼šï¼‰
                    filtered_signals.append(s)
            
            if filtered_signals:
                signals = filtered_signals
                logger.info(f"   ğŸ” æ¿å—æ»¤ç½‘: ä¿ç•™ {len(signals)} åª (æ¿å—æ’åå‰{int(top_pct*100)}%)")
    except Exception as e:
        logger.warning(f"æ¿å—æ»¤ç½‘å¤±è´¥: {e}")
    
    # =========================================
    # å‡¯åˆ©å…¬å¼ä»“ä½è®¡ç®— (v2.3.1 æ–°å¢)
    # =========================================
    try:
        from config import KELLY_POSITION
        from src.indicators import calculate_dynamic_position_size
        
        if KELLY_POSITION.get('enabled', True):
            base_amount = KELLY_POSITION.get('base_amount', 50000)
            kelly_result = calculate_dynamic_position_size(base_amount)
            
            logger.info(f"\nğŸ’° å‡¯åˆ©å…¬å¼ä»“ä½å»ºè®®:")
            logger.info(f"   å†å²èƒœç‡: {kelly_result['win_rate']*100:.1f}%")
            logger.info(f"   å»ºè®®é‡‘é¢: {kelly_result['suggested_amount']:.0f} å…ƒ ({kelly_result['adjustment']})")
            
            # v2.5.1: å¸‚åœºå®½åº¦æ·±åº¦è”åŠ¨
            # breadth > 15%: ä»“ä½åŠ æˆ 1.2x (æå¼ºå¸‚åœº)
            # breadth 8-15%: æ­£å¸¸ä»“ä½ 1.0x
            # breadth 4-8%: ä»“ä½å‡åŠ 0.5x (å·²åœ¨å‰é¢è®¾ç½®)
            if position_multiplier == 1.0 and breadth_pct > 15:
                position_multiplier = 1.2
                logger.info(f"   ğŸ“ˆ å¸‚åœºå®½åº¦æå¼º ({breadth_pct}%)ï¼Œä»“ä½åŠ æˆ Ã—1.2")
            
            adjusted_amount = kelly_result['suggested_amount'] * position_multiplier
            for s in signals:
                current_price = s.get('close', 0)
                if current_price > 0:
                    suggested_vol = int(adjusted_amount / current_price / 100) * 100
                    s['suggested_volume'] = f"{suggested_vol} è‚¡"
                    s['suggested_amount'] = adjusted_amount
            
            if position_multiplier < 1.0:
                logger.info(f"   âš ï¸ å·²åº”ç”¨å¸‚åœºå®½åº¦é£æ§: å»ºè®®é‡‘é¢ Ã— {position_multiplier:.0%}")
    except Exception as e:
        logger.warning(f"å‡¯åˆ©å…¬å¼è®¡ç®—å¤±è´¥: {e}")
    # =========================================
        
    # æŒ‰ç»¼åˆå¾—åˆ†æˆ–RPSæ’åº
    results_df = pd.DataFrame(signals)
    if 'total_score' in results_df.columns:
        results_df = results_df.sort_values(by='total_score', ascending=False)
    else:
        results_df = results_df.sort_values(by='rps', ascending=False)
    
    # =========================================
    # v2.5.1: å‰10åäºŒæ¬¡ç¡®è®¤ - æ•´åˆå°¾ç›˜æ•°æ®ä¸ç­¹ç å› å­ (ASR)
    # é™åˆ¶é«˜é¢‘ API è°ƒç”¨èŒƒå›´ï¼Œä¿éšœè´¦å·å®‰å…¨
    # =========================================
    try:
        top_codes = results_df.head(10)['code'].tolist()
        if top_codes:
            logger.info(f"\nğŸ”¬ å‰10åäºŒæ¬¡ç¡®è®¤: è·å–å°¾ç›˜å¸ç­¹æ•°æ®...")
            
            for code in top_codes:
                try:
                    idx = results_df[results_df['code'] == code].index
                    if len(idx) == 0: continue
                    idx_val = idx[0]
                    
                    # 1. éªŒè¯å°¾ç›˜æ•°æ® (æ„å›¾è¯†åˆ«)
                    tail_data = get_tail_volume_ratio(code)
                    tail_ratio = tail_data['ratio']
                    tail_change = tail_data['price_change']
                    
                    if tail_ratio > 15:
                        if tail_change > 0.5:
                            # v2.5.2: å¼ºåŠ›å¸ç­¹ (æ”¾é‡ + ä¸Šæ¶¨ > 0.5%)
                            results_df.loc[idx_val, 'remark'] = f"âœ¨å°¾ç›˜å¼ºå¸ç­¹({tail_ratio:.0f}%, {tail_change:+.1f}%)"
                            results_df.loc[idx_val, 'total_score'] += min(tail_ratio / 2, 15)  # åŠ åˆ†ä¸Šé™æé«˜
                        elif tail_change > 0:
                            # æ„å›¾è¯†åˆ«ï¼šé‡å¢ä»·ç¨³/å‡ -> ç§¯æå¸ç­¹
                            results_df.loc[idx_val, 'remark'] = f"âœ¨å°¾ç›˜å¸ç­¹({tail_ratio:.0f}%, {tail_change:+.1f}%)"
                            results_df.loc[idx_val, 'total_score'] += min(tail_ratio / 2, 10)
                        elif tail_change < -0.5:
                            # v2.5.2: æ”¾é‡ä¸‹è·Œç›´æ¥å‰”é™¤ (åŸ -1.0% æ”¹ä¸º -0.5%)
                            # ç­–ç•¥å¸ˆå»ºè®®ï¼šæ¬¡æ—¥ä½å¼€æ¦‚ç‡æé«˜ï¼Œå³ä½¿ Grade A ä¹Ÿä¸åº”å‚ä¸
                            results_df.loc[idx_val, 'remark'] = f"ğŸš«å°¾ç›˜ç ¸ç›˜({tail_ratio:.0f}%, {tail_change:.1f}%)"
                            results_df.loc[idx_val, '_exclude'] = True  # æ ‡è®°å¾…å‰”é™¤
                            logger.warning(f"   âš ï¸ {code} å°¾ç›˜æ”¾é‡ç ¸ç›˜ ({tail_change:.1f}%)ï¼Œå·²å‰”é™¤")
                        else:
                            # å¾®è·Œä½†æ”¾é‡ï¼Œç»™äºˆè­¦å‘Š
                            results_df.loc[idx_val, 'remark'] = f"âš ï¸å°¾ç›˜å¼‚åŠ¨({tail_ratio:.0f}%, {tail_change:.1f}%)"
                            results_df.loc[idx_val, 'total_score'] -= 3

                    # 2. éªŒè¯ç­¹ç å› å­
                    from src.factors import get_shareholder_change_score, calculate_rps_slope, get_rps_history_for_code
                    chip_info = get_shareholder_change_score(code)
                    if chip_info['score'] > 60:
                        existing = results_df.loc[idx_val, 'remark'] if 'remark' in results_df.columns and pd.notna(results_df.loc[idx_val, 'remark']) else ""
                        results_df.loc[idx_val, 'remark'] = f"{existing} {chip_info['label']}".strip()
                        results_df.loc[idx_val, 'total_score'] += 5
                    
                    # 3. v2.5.2: RPS åŠ¨é‡æ–œç‡éªŒè¯
                    rps_history = get_rps_history_for_code(code, days=5)
                    if rps_history:
                        slope_info = calculate_rps_slope(rps_history)
                        adjustment = slope_info['score_adjustment']
                        if adjustment != 0:
                            results_df.loc[idx_val, 'total_score'] += adjustment
                            existing = results_df.loc[idx_val, 'remark'] if 'remark' in results_df.columns and pd.notna(results_df.loc[idx_val, 'remark']) else ""
                            results_df.loc[idx_val, 'remark'] = f"{existing} {slope_info['label']}".strip()
                            if adjustment > 0:
                                logger.debug(f"   {code} {slope_info['label']}, è¯„åˆ† +{adjustment}")
                            else:
                                logger.debug(f"   {code} {slope_info['label']}, è¯„åˆ† {adjustment}")
                except Exception as e:
                    logger.debug(f"äºŒæ¬¡éªŒè¯å¤±è´¥ {code}: {e}")
            
            # v2.5.1: å‰”é™¤å°¾ç›˜ç ¸ç›˜æ ‡çš„
            if '_exclude' in results_df.columns:
                exclude_count = results_df['_exclude'].sum() if results_df['_exclude'].notna().any() else 0
                if exclude_count > 0:
                    results_df = results_df[results_df['_exclude'] != True]
                    results_df = results_df.drop(columns=['_exclude'], errors='ignore')
                    logger.info(f"   ğŸš« å·²å‰”é™¤ {int(exclude_count)} åªå°¾ç›˜ç ¸ç›˜æ ‡çš„")
            
            # é‡æ–°æ’åº
            if 'total_score' in results_df.columns:
                results_df = results_df.sort_values(by='total_score', ascending=False)
    except Exception as e:
        logger.warning(f"å°¾ç›˜äºŒæ¬¡ç¡®è®¤å¤±è´¥: {e}")
    
    # ä¿å­˜ç»“æœ
    today = datetime.datetime.now().strftime('%Y%m%d')
    output_path = os.path.join(RESULTS_DIR, f"é€‰è‚¡ç»“æœ_{today}.csv")
    results_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    logger.info("\n" + "=" * 60)
    logger.info(f"âœ¨ é€‰è‚¡å®Œæˆï¼å‘½ä¸­ {len(results_df)} åª")
    logger.info(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    logger.info("-" * 60)
    
    # æ‰“å°ç»“æœ (æ ¹æ®æ˜¯å¦æœ‰å¤šå› å­è¯„åˆ†é€‰æ‹©æ˜¾ç¤ºåˆ—)
    if 'total_score' in results_df.columns:
        cols = ['ä»£ç ', 'åç§°', 'ç°ä»·', 'total_score', 'grade', 'åˆ†ç±»']
        results_df = results_df.rename(columns={'total_score': 'ç»¼åˆè¯„åˆ†', 'grade': 'è¯„çº§'})
        cols = ['ä»£ç ', 'åç§°', 'ç°ä»·', 'ç»¼åˆè¯„åˆ†', 'è¯„çº§', 'åˆ†ç±»']
    else:
        cols = ['ä»£ç ', 'åç§°', 'ç°ä»·', 'RPS', 'åˆ†ç±»']
    
    if 'å»ºè®®ä¹°å…¥' in results_df.columns:
        cols.append('å»ºè®®ä¹°å…¥')
    
    available_cols = [c for c in cols if c in results_df.columns]
    print_df = results_df.head(10)[available_cols]
    logger.info(print_df.to_string(index=False))
    logger.info("=" * 60)
    
    # =========================================
    # æ¿å—æ•ˆåº”åˆ†æ (v2.4 æ–°å¢)
    # =========================================
    try:
        from src.factors import print_sector_cluster_report
        print_sector_cluster_report(signals)
    except Exception as e:
        logger.warning(f"æ¿å—æ•ˆåº”åˆ†æå¤±è´¥: {e}")
    
    # è‡ªåŠ¨è®°å½•æ¨èç”¨äºæ•ˆæœè¿½è¸ª
    try:
        from src.tasks.performance_tracker import record_daily_recommendations
        record_daily_recommendations(signals)
    except Exception as e:
        logger.warning(f"è®°å½•æ¨èå¤±è´¥: {e}")
    
    # è‡ªåŠ¨åŠ å…¥è™šæ‹ŸæŒä»“è¿›è¡Œç­–ç•¥éªŒè¯
    try:
        from src.tasks.virtual_tracker import add_recommendations_to_virtual
        add_recommendations_to_virtual(signals)
    except Exception as e:
        logger.warning(f"åŠ å…¥è™šæ‹ŸæŒä»“å¤±è´¥: {e}")
    
    # è¿”å›ç»“æœä¾›è°ƒç”¨æ–¹(å¦‚ main.py)å¤„ç†é€šçŸ¥é€»è¾‘
    return signals


if __name__ == "__main__":
    run_scan()
